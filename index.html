<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title> Hexo </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Hexo</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/03/08/qa-cnn/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="ustcJin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/heart_scale.png">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Hexo">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Hexo" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/08/qa-cnn/" itemprop="url">
                  CNN在问答领域识别中应用
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-08T18:51:28+08:00">
                2017-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>短文本question-answer匹配度识别问题，论文(Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks.pdf), github<a href="https://github.com/aseveryn/deep-qa" target="_blank" rel="external">实现</a>。github的作者基本上实现了文章里的算法，计算的精度也差不多，不过使用theano实现的，我准备使用tensorflow实现，并解决大规模预料训练太慢的问题。当然本文要开始从分析git的实现开始讲起，会穿插theano的一些语法，实现等，我自己也是从零学起的，且当给自己留个笔记吧。</p>
<h1 id="架构？"><a href="#架构？" class="headerlink" title="架构？"></a>架构？</h1><p>不能不提到的论文中经典的架构图。<br><img src="/images/deep_qa.jpg" alt=""><br>网络用文字梳理的结果如下:</p>
<ol>
<li>question answer并行处理成词向量</li>
<li>词向量与卷积核做运算得到n个dim维的向量</li>
<li>对2中得到的向量做Activation和Pooling处理，得到1维数组，大小为n</li>
<li>问题和答案抽出的1维数组分别与相似度矩阵M做乘积预算，得到相似度，即$A*M*Q=sim$</li>
<li>计算answer和question中的相同部分F，将A,sim,Q,F拼接成新的向量</li>
<li>将5中得到的向量做线性变化，即$\alpha(W*X+b)$</li>
<li>最后使用Softmax对6中得到的linear之后的向量做分类</li>
</ol>
<h2 id="使用theano的实现"><a href="#使用theano的实现" class="headerlink" title="使用theano的实现"></a>使用theano的实现</h2><p>作者的实现有一些改动，如第5步骤中计算得到的交叉部分F，这部分可以是交叉词的词向量，也可以是交叉词的idf，比重等，显然idf和比重更容易让人信服，不过这个值不好处理，作者并没有用，而是直接使用的交叉词的词向量直接拼到qustion和answer的词向量中，即将这部分直接放到开头做了。</p>
<h2 id="数据预处理-embedding"><a href="#数据预处理-embedding" class="headerlink" title="数据预处理(embedding)"></a>数据预处理(embedding)</h2><p>这部分主要是将question-answer对分词(英文就是空格直接分词), 然后根据word2vec，将问题和答案分解成word2vec的词向量，并收集全集词表，word2vec缺失的词使用默认值填充。难点在于训练集合的选取，这是有监督的学习，对于中文的海量语法来说，需要的训练集合的规模也是非常大的。</p>
<h2 id="Load"><a href="#Load" class="headerlink" title="Load"></a>Load</h2><p>主要load的数据有train, dev, test三类，train是训练参数使用，dev是验证参数，test是实测使用，其实dev和test可以归为一类，每类数据分为question, answer, overlap。</p>
<h2 id="词向量转化"><a href="#词向量转化" class="headerlink" title="词向量转化"></a>词向量转化</h2><p>LookupTableFast将question, answer, overlap转化为词向量。这里会讲pad部分(即卷积的宽度补上)，最呕输出的是[batch_size, 1, 2 * (q_size + q_filter_widths - 1), ndim], ndim是词向量的宽度(word2vec生成的词向量的size)，后面ndim的长度会拓展为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># sentence长度 + 交叉长度</div><div class="line">ndim = vocab_emb.shape[1] + vocab_emb_overlap.shape[1]</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">class LookupTableFastStatic(Layer):</div><div class="line">	def __init__(self, W=None, pad=None):</div><div class="line">		super(LookupTableFastStatic, self).__init__()</div><div class="line">		self.pad = pad</div><div class="line">		self.W = theano.shared(value=W, name=&apos;W_emb&apos;, borrow=True)</div><div class="line"></div><div class="line">		def output_func(self, input):</div><div class="line">			out = self.W[input.flatten()].reshape((input.shape[0], 1, input.shape[1], self.W.shape[1]))</div><div class="line">			if self.pad:</div><div class="line">				pad_matrix = T.zeros((out.shape[0], out.shape[1], self.pad, out.shape[3]))</div><div class="line">	  			out = T.concatenate([pad_matrix, out, pad_matrix], axis=2)</div><div class="line">	  		return out</div><div class="line"></div><div class="line">	  def __repr__(self):</div><div class="line">		  return &quot;&#123;&#125;: &#123;&#125;&quot;.format(self.__class__.__name__, self.W.shape.eval())</div></pre></td></tr></table></figure>
<h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p>定义Conv2dLayer来做卷积类使用，卷积的初始化如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">def __init__(self, rng, filter_shape, input_shape=None, W=None):</div><div class="line"># @rng: 初始化种子</div><div class="line"># @filter_shape: 卷积核的样式，filter_shape = (nkernels, num_input_channels, filter_width, ndim), nkernels = 100, num_input_channels = 1, 可见与question长度无关。</div><div class="line"># @input_shape: 同上一层词向量层的输出</div><div class="line"># @self.W 也和filter_shape具有相同的shape，随机化一些数字</div></pre></td></tr></table></figure></p>
<p>卷积使用库函数，调用如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">def output_func(self, input):</div><div class="line">	return conv.conv2d(input, self.W, border_mode=&apos;valid&apos;,</div><div class="line">			filter_shape=self.filter_shape,</div><div class="line">			image_shape=self.input_shape)</div></pre></td></tr></table></figure></p>
<p>看看<code>conv2d</code>函数的返回, 看到output的是$[batch_size, filter_size, sentence_size, ndim]$<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Parameters:	</div><div class="line">input (dmatrix of dtensor3) – Symbolic variable for images to be filtered.</div><div class="line">filters (dmatrix of dtensor3) – Symbolic variable containing filter values.</div><div class="line">border_mode (&#123;&apos;valid&apos;, &apos;full&apos;&#125;) – See scipy.signal.convolve2d.</div><div class="line">subsample – Factor by which to subsample output.</div><div class="line">image_shape (tuple of length 2 or 3) – ([number images,] image height, image width).</div><div class="line">filter_shape (tuple of length 2 or 3) – ([number filters,] filter height, filter width).</div><div class="line">kwargs – See theano.tensor.nnet.conv.conv2d.</div><div class="line">Returns:	</div><div class="line">Tensor of filtered images, with shape ([number images,] [number filters,] image height, image width)</div></pre></td></tr></table></figure></p>
<p><strong>何为卷积？如何卷积?</strong><br>卷积为分时加权，在词向量上表现为分段计算作为权重，粒度更细了，input_shape细化为单个qa，即为如下格式(加上filter_width)。<br>$$<br>S =<br>\begin{vmatrix}<br>|    &amp; |    &amp;    …    &amp; | &amp; | \\<br>filter &amp; w_1 &amp; … &amp; w_{|s|} &amp; filter \\<br>|    &amp; |    &amp;    …    &amp; | &amp; | \\<br>\end{vmatrix}<br>$$<br>$S.shape = [ndim, 2 \cdot (filter - 1) + len(s)]$<br>卷积核为[dim, m]维度，卷积公式如下:<br>$c_i=S \cdot f=S^T_{[i-m+1]} \cdot f=\sum_{k=i}^{i+m-1} s_kf_k$<br>注意是S的转置矩阵与f的相乘, 最后得到的是$[2 \cdot filter + |s|]$的宽度数组，即为卷积结果。增加filter_width是为了让S的每个word享受到相同的卷积效果。</p>
<h2 id="Activation-tanh"><a href="#Activation-tanh" class="headerlink" title="Activation (tanh)"></a>Activation (tanh)</h2><p>使用nn_layers.NonLinearityLayer作为主类，初始化以及output函数:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">NonLinearityLayer(b_size=filter_shape[0], activation=activation)</div><div class="line"></div><div class="line">def output_func(self, input):</div><div class="line">	return self.activation(input + self.b.dimshuffle(&apos;x&apos;, 0, &apos;x&apos;, &apos;x&apos;))</div></pre></td></tr></table></figure></p>
<p>dimshuffle是将b拓展到4维，正好与卷积的output匹配相加。这里有一个问题，卷积出的第四维度是ndim，和公式算的$c_i$没有该维度，该维度上直接相加了。</p>
<h1 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h1>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/15/Xgboost/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="ustcJin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/heart_scale.png">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Hexo">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Hexo" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/15/Xgboost/" itemprop="url">
                  Xgboost源码阅读
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-15T14:25:57+08:00">
                2017-02-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><code>xgboost</code>是有监督学习的利器，相较于与决策树、随机森林、gbdt等都有着明显优势，也许是各个算法有自己适用的领域吧。<code>xgboost</code>厉害之处在于同时控制了残差和复杂度，在迭代优化过程中，会同时考量这两个因素，本文会按照我自己的学习时的思路来介绍该算法，包括陈天奇(天才少年)的C++源码解读。</p>
<h1 id="带着问题走"><a href="#带着问题走" class="headerlink" title="带着问题走"></a>带着问题走</h1><p>由于之前也是使用了挺多的算法，包括dtree, random forest, 还有各种pair wise、list wise算法，但是听到同事的介绍还是产生了兴趣，我本人介入机器学习领域时间较短，开始在听完<code>xgboost</code>的介绍时，就迫切的想了解两个东西: </p>
<blockquote>
<p>xgboost如何并行化？<br>xgboost是如何控制复杂度的?<br>xgboost如何选择最优分裂?</p>
</blockquote>
<p>这三个问题是我继续了解的动力，另外后面的阅读和学习中，又知道了关于<code>xgboost</code>的最优化split、最优化Gain等详细知识，另外还有各种objective 灵活设置，非常方便。有些材料仅供参考:</p>
<blockquote>
<p>xgboost<a href="xgboost.readthedocs.io/en/latest/">官网</a>，<a href="https://github.com/dmlc/xgboost" target="_blank" rel="external">github</a><br>某乎较好的<a href="https://www.zhihu.com/question/41354392" target="_blank" rel="external">帖子</a><br>blog<a href="http://blog.csdn.net/chedan541300521/article/details/54895880" target="_blank" rel="external">地址</a><br>陈天奇<a href="http://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf" target="_blank" rel="external">slides</a><br>陈天奇<a href="https://arxiv.org/abs/1603.02754" target="_blank" rel="external">paper</a></p>
</blockquote>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍?"></a>原理介绍?</h1><p>基本的概念如tree, mart, residual等就不介绍了，直接进入主题，<code>xgboost</code>的目标函数:<br>                             $Obj(\theta) = L(\theta) + \Omega(\theta)$<br>$\theta$是我们要求的最优解，可以对应<code>xgboost</code>上各个<code>tree</code>上最有<code>split</code>和最有<code>leaf value</code>，$L$是残差，即模型预测值和实际训练样本的差值，当然是越小越好，$\Omega$是模型复杂度，这个也很重要，防止过拟合以及严重的抖动，一般模型需要做<code>bias</code>和<code>varience</code>的校验，一个对应$L$，一个对应$\Omega$。<code>xgboost</code>是<code>mart</code>，预测值是所有的<code>tree</code>的加权相加:<br>$\hat{y_i}=\sum_{i=1}^{K}f_k(x_i),f_k \in{\mathcal{F}}$<br>以上是mart建立之后如何预测，tree建立在分裂时，会有目标，<code>Objective</code>细化为<br>$Obj=\sum_{i=1}^{n} l(y_i, \hat{y_i})+\sum_{k=1}^{K} \Omega(f_i)<br>=\sum_{i=1}^{n}l(y_i, \hat y_i^{t-1} + f_t(x_i)) + \Omega(f_t) + constant $<br>$f_t$是第t轮迭代，即第t颗树，由于t轮之前的参数已经确定，所以最后归结为<code>constant</code>，目标也是寻找最优的$f_t$，让<code>Obj</code>最小。<br>使用二阶泰勒展开的方式<br>$f(x+\Delta{x}) \approx f(x) + f’(x)\Delta{x} + \frac{1}{2}f’’(x)\Delta{x^2}$<br>做一下转化:</p>
<blockquote>
<p>$l(y_i, \hat y_i^{t-1} + f_t(x_i)) =&gt; f(x+\Delta{x}) $<br>$g_i=\delta_{\hat y_i^{t-1}}{l(y_i, \hat{y}^{(t-1)})}$<br>$h_i=\delta_{\hat y_i^{t-1}}^2 {l(y_i, \hat{y}^{(t-1)})}$</p>
</blockquote>
<p>则<code>Obj</code>在t轮迭代的目标为<br>$Obj=\sum_{i=1}^{n}l(y_i, \hat y_i^{t-1} + f_t(x_i)) + \Omega(f_t) + constant<br>=\sum_{i=1}^{n}[l(y_i, \hat y_i^{t-1}) + g_if_t(x_i) + \frac{1}{2}h_if_t^2(x_i)] + \Omega(f_t) + constant$<br>模型复杂度$\Omega(f_t)$的定义：<br>$\Omega(f_t)=\gamma{T} + \frac{1}{2}\lambda\sum_{j=1}^{T}w_j{^2}$<br>$T$是叶子节点的个数，$w_j$是叶子节点对叶的<code>leaf_score</code>,进一步化简$Obj(f_t)$:<br>$Obj=\sum_{i=1}^{n}[g_if_t(x_i) + \frac{1}{2}h_if_t^2(x_i)] + \Omega(f_t)<br>=\sum_{i=1}^{n}[g_iw_{q(x_i)} + \frac{1}{2}h_iw^2_{q(x_i)}] + \gamma{T} + \frac{1}{2}\lambda\sum_{j=1}^{T}w_j{^2}$<br>$=\sum_{j=1}^{T}[(\sum_{i \in I_j}g_i)w_j + \frac{1}{2}(\sum_{i \in I_j}h_i + \lambda)w^2_j] + \gamma T$</p>
<p>这样终于看出GBDT计算收益的最终公式了：<br>$(1) w_j = - \frac{G_j}{H_j+\lambda}$<br>$(2) Obj =- \frac{1}{2}\sum_{j=1}^{T}\frac{G^2_j}{H_j + \lambda} + \gamma T$<br>$(3) Gain = \frac{1}{2}[\frac{G^2_L}{H_L+\lambda} + \frac{G^2_R}{H_R+\lambda} - \frac{(G_L + G_R)^2}{H_L + H_R + \lambda}] - \gamma$</p>
<p>$\gamma$就是<del>传说中的一阶正则项</del>，$\gamma$是后面提到的参数<code>min_split_loss</code>，剪枝使用，太小的收益不必分裂。树节点分裂的收益达到某个值后再分裂，而二阶正则项$\lambda$主要是为了防止过拟合, 增强模型的稳定性。</p>
<h1 id="如何并行化？"><a href="#如何并行化？" class="headerlink" title="如何并行化？"></a>如何并行化？</h1><p>xgboost相对于gbdt是有一个并行的优势，怎么并行的呢，下面会读数据并行化和树分裂时的并行化分两部分介绍</p>
<h2 id="读数据并行"><a href="#读数据并行" class="headerlink" title="读数据并行"></a>读数据并行</h2><p>开始的输入数据是libsvm格式，形如”1 1:1.2 2:2.1 3:3.5 …”一行一行的数据，训练集合可能会非常大，大家都知道xgboost会枚举所有的特征值，选用最佳分割，所以开始是需要按列把各个feature排序好，这一步在xgboost里是并行做的。。。xgboost使用DMatrix存储训练数据，每次训练前会调用InitColAccess()将行训练数据支持按列取的数据，这里是通过MakeOneBatch多线程来实现的，这么多列属性的排序被n个线程平分，最后将数据转化成 key,value的方式，key是列id，value是rowid, val的pair，rowid是该列所对应的行编号，用于拿出整行训练数据的信息，val是该行该列下的具体数字，这个信息最后会存入DMatrix的SparsePage中，可知道最后是存了feature_num个实际train_set，用于训练阶段方便的取数据，不用做重复的排序工作了。</p>
<h2 id="分裂选择并行化"><a href="#分裂选择并行化" class="headerlink" title="分裂选择并行化"></a>分裂选择并行化</h2><p>tree进行分裂的时候会考量每个feature的每个value，如果串行计算，肯定会比较慢，xgboost使用了并行化，多个线程综合考虑每个列的情况，主要在FindSplit()里做的<br>● this-&gt;UpdateSolution(iter-&gt;Value(), gpair, *p_fmat); 主函数，枚举每一个feature，的每一个value，尝试收益<br>● this-&gt;SyncBestSolution(qexpand); 多线程merger，当前node的最好的split<br>● sync solution; 同步成果，给tree建node，左右儿子等<br>每个线程会枚举自己的feature的各个split value，将最佳分裂保存到当前线程的结构中，最后所有的线程会根据各自的best split做merge，从而找到当前tree的最佳分裂，这里也用到了并行化，共享了读数据阶段产生的SparsePage</p>
<p>这些并行化和共享让xgboost的训练速度非常快。以上基本上解决了我开始的三个疑问，下面说一些xgboost的细节。</p>
<h2 id="细节1-tree如何维护当前的数据集？"><a href="#细节1-tree如何维护当前的数据集？" class="headerlink" title="细节1: tree如何维护当前的数据集？"></a>细节1: tree如何维护当前的数据集？</h2><p>这个是通过postion这个vector来实现的，vector是训练机的大小，每个值代表当前训练样本属于的树节点编号，开始都是0，即开始所有的样本都是在根节点上。expand这个vector保存当前叶子节点，即即将开始下一轮分裂的叶子节点编号，当然开始也是初始化为0，postion里的所有值都是取自于expand</p>
<h2 id="细节2-模型复杂度"><a href="#细节2-模型复杂度" class="headerlink" title="细节2: 模型复杂度"></a>细节2: 模型复杂度</h2><p>主要说下$\gamma,\alpha, \lambda$这三个，这三个控制这模型复杂度。</p>
<ul>
<li>$\gamma$是<code>min_split_loss</code>，控制树的分裂深度，收益必须大于该值才分裂。</li>
<li><p>$\alpha$是一阶正则项，也是控制复杂度的，不过比较弱，一般训练设置为0，控制这Grad(一阶梯度)不至于过大或者过小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">if (p.reg_alpha == 0.0f) &#123;</div><div class="line">	return Sqr(sum_grad) / (sum_hess + p.reg_lambda);</div><div class="line">&#125; else &#123;</div><div class="line">	return Sqr(ThresholdL1(sum_grad, p.reg_alpha)) /</div><div class="line">		(sum_hess + p.reg_lambda);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>$\lambda$是二阶正则项，具体使用上面的推到也已经明了了</p>
</li>
</ul>
<h1 id="应用参数"><a href="#应用参数" class="headerlink" title="应用参数"></a>应用参数</h1><p>首先推荐官方的API，这个没有更权威的了，如果使用，一定要仔细阅读，我是在python中使用，所以会看<a href="http://xgboost.readthedocs.io/en/latest/python/python_api.html" target="_blank" rel="external">python的API</a>)。首先说一下命令行版本也就是github拉下来之后直接编译出的二进制，直接使用”./xgboost config.ini”的方式即可，注意配置的格式，其实参考”src/cli_main.cc”也可以大概看出需要配置那些参数，我贴一下自己的训练配置和预测配置:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">● train.conf</div><div class="line">train_path=/Users/wang/company/ltr/ask.train</div><div class="line">model_out=/Users/wang/company/ltr/module.out.1</div><div class="line">objective=rank:ndcg</div><div class="line">num_round=200</div><div class="line">eval_metric=ndcg@3-</div><div class="line">task=train</div><div class="line">eval_train=true</div><div class="line">max_depth=4</div><div class="line">min_split_loss=0.2</div><div class="line">reg_lambda=2.0</div><div class="line"></div><div class="line">● test.conf</div><div class="line">test_path=feature.ask</div><div class="line">name_pred=pred.txt</div><div class="line">model_in=module.out</div><div class="line">objective=rank:ndcg</div><div class="line">task=pred</div></pre></td></tr></table></figure></p>
<p>源码中是使用<a href="https://github.com/dmlc/dmlc-core" target="_blank" rel="external">dmlc-core</a>来做的参数处理，十分方便，我是做搜索排序相关，所以目标使用<code>ndcg, reg_lambda</code>对应上面所说的$\lambda$，<code>min_split_loss</code>是树分裂所达到的最小收益值，即上面公式(3)中的Gain，一阶正则项$\alpha＝0$。<br>不过还是推荐使用python版本，python版本在训练时，可以看到每轮之后test集的准确度(ndcg值)，可以直观的看到效果，主要是param的设置，如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># param</div><div class="line">param = &#123;&apos;eval_metric&apos;: &apos;ndcg@3-&apos;, &apos;base_score&apos;: 0.0, &apos;max_leaves&apos;: 10, &apos;alpha&apos;: 0.0, &apos;tree_method&apos;: &apos;exact&apos;, &apos;bagging&apos;: 3, &apos;silent&apos;: 1, &apos;grow_policy&apos;: &apos;depthwise&apos;, &apos;subsample&apos;: 1.0, &apos;eta&apos;: 0.2, &apos;max_bin&apos;: 256, &apos;objective&apos;: &apos;rank:ndcg&apos;, &apos;max_depth&apos;: 4, &apos;gamma&apos;: 0.2, &apos;lambda&apos;: 2.0&#125;</div><div class="line"></div><div class="line">#设置测试集合的train</div><div class="line">num_round = 200</div><div class="line">dtrain.set_group(numpy.loadtxt(&apos;../../company/ltr/ask.train.group&apos;, dtype=numpy.int32))</div><div class="line">dtest.set_group(numpy.loadtxt(&apos;../../company/ltr/ask.test.group&apos;, dtype=numpy.int32))</div><div class="line">bst = xgb.train(param, dtrain, num_round, [(dtrain, &apos;train&apos;), (dtest, &apos;test&apos;)])</div></pre></td></tr></table></figure></p>
<p>最后贴一张训练截图<br><img src="/images/xgboost_ndcg.jpg" alt="ndcg"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  

          
          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/heart_scale.png"
               alt="ustcJin" />
          <p class="site-author-name" itemprop="name">ustcJin</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ustcJin</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  





  



  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  


</body>
</html>
