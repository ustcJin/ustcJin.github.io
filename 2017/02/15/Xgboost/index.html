<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>Xgboost源码阅读 | Hexo</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="it,ml">
    <meta name="description" content="前言xgboost是有监督学习的利器，相较于与决策树、随机森林、gbdt等都有着明显优势，也许是各个算法有自己适用的领域吧。xgboost厉害之处在于同时控制了残差和复杂度，在迭代优化过程中，会同时考量这两个因素，本文会按照我自己的学习时的思路来介绍该算法，包括陈天奇(天才少年)的C++源码解读。
带着问题走由于之前也是使用了挺多的算法，包括dtree, random forest, 还有各种pa">
<meta property="og:type" content="article">
<meta property="og:title" content="Xgboost源码阅读">
<meta property="og:url" content="http://yoursite.com/2017/02/15/Xgboost/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="前言xgboost是有监督学习的利器，相较于与决策树、随机森林、gbdt等都有着明显优势，也许是各个算法有自己适用的领域吧。xgboost厉害之处在于同时控制了残差和复杂度，在迭代优化过程中，会同时考量这两个因素，本文会按照我自己的学习时的思路来介绍该算法，包括陈天奇(天才少年)的C++源码解读。
带着问题走由于之前也是使用了挺多的算法，包括dtree, random forest, 还有各种pa">
<meta property="og:image" content="http://yoursite.com/images/xgboost_ndcg.jpg">
<meta property="og:updated_time" content="2017-06-14T11:51:06.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Xgboost源码阅读">
<meta name="twitter:description" content="前言xgboost是有监督学习的利器，相较于与决策树、随机森林、gbdt等都有着明显优势，也许是各个算法有自己适用的领域吧。xgboost厉害之处在于同时控制了残差和复杂度，在迭代优化过程中，会同时考量这两个因素，本文会按照我自己的学习时的思路来介绍该算法，包括陈天奇(天才少年)的C++源码解读。
带着问题走由于之前也是使用了挺多的算法，包括dtree, random forest, 还有各种pa">
<meta name="twitter:image" content="http://yoursite.com/images/xgboost_ndcg.jpg">
    
        <link rel="alternate" type="application/atom+xml" title="Hexo" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">ustcJin</h5>
          <a href="mailto:452697589@qq.com" title="452697589@qq.com" class="mail">452697589@qq.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/yscoder" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="http://www.weibo.com/ysweb" target="_blank" >
                <i class="icon icon-lg icon-weibo"></i>
                Weibo
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/custom"  >
                <i class="icon icon-lg icon-link"></i>
                测试
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Xgboost源码阅读</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Xgboost源码阅读</h1>
        <h5 class="subtitle">
            
                <time datetime="2017-02-15T06:25:57.000Z" itemprop="datePublished" class="page-time">
  2017-02-15
</time>


            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#前言"><span class="post-toc-number">1.</span> <span class="post-toc-text">前言</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#带着问题走"><span class="post-toc-number">2.</span> <span class="post-toc-text">带着问题走</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#原理介绍"><span class="post-toc-number">3.</span> <span class="post-toc-text">原理介绍?</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#如何并行化？"><span class="post-toc-number">4.</span> <span class="post-toc-text">如何并行化？</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#读数据并行"><span class="post-toc-number">4.1.</span> <span class="post-toc-text">读数据并行</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#分裂选择并行化"><span class="post-toc-number">4.2.</span> <span class="post-toc-text">分裂选择并行化</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#细节1-tree如何维护当前的数据集？"><span class="post-toc-number">4.3.</span> <span class="post-toc-text">细节1: tree如何维护当前的数据集？</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#细节2-模型复杂度"><span class="post-toc-number">4.4.</span> <span class="post-toc-text">细节2: 模型复杂度</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Lambda-Object"><span class="post-toc-number">5.</span> <span class="post-toc-text">Lambda Object</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#问题1-如何做到好的结果按照NDCG更快排上去的"><span class="post-toc-number">5.1.</span> <span class="post-toc-text">问题1:如何做到好的结果按照NDCG更快排上去的?</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#问题2-好的结果每次都会加权，最后预测值会很大？"><span class="post-toc-number">5.2.</span> <span class="post-toc-text">问题2:好的结果每次都会加权，最后预测值会很大？</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#应用参数"><span class="post-toc-number">6.</span> <span class="post-toc-text">应用参数</span></a></li></ol>
        </nav>
    </aside>


<article id="post-Xgboost"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Xgboost源码阅读</h1>
        <div class="post-meta">
            <time class="post-time" title="2017-02-15 14:25:57" datetime="2017-02-15T06:25:57.000Z"  itemprop="datePublished">2017-02-15</time>

            


            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><code>xgboost</code>是有监督学习的利器，相较于与决策树、随机森林、gbdt等都有着明显优势，也许是各个算法有自己适用的领域吧。<code>xgboost</code>厉害之处在于同时控制了残差和复杂度，在迭代优化过程中，会同时考量这两个因素，本文会按照我自己的学习时的思路来介绍该算法，包括陈天奇(天才少年)的C++源码解读。</p>
<h1 id="带着问题走"><a href="#带着问题走" class="headerlink" title="带着问题走"></a>带着问题走</h1><p>由于之前也是使用了挺多的算法，包括dtree, random forest, 还有各种pair wise、list wise算法，但是听到同事的介绍还是产生了兴趣，我本人介入机器学习领域时间较短，开始在听完<code>xgboost</code>的介绍时，就迫切的想了解两个东西: </p>
<blockquote>
<p>xgboost如何并行化？<br>xgboost是如何控制复杂度的?<br>xgboost如何选择最优分裂?</p>
</blockquote>
<p>这三个问题是我继续了解的动力，另外后面的阅读和学习中，又知道了关于<code>xgboost</code>的最优化split、最优化Gain等详细知识，另外还有各种objective 灵活设置，非常方便。有些材料仅供参考:</p>
<blockquote>
<p>xgboost<a href="xgboost.readthedocs.io/en/latest/">官网</a>，<a href="https://github.com/dmlc/xgboost" target="_blank" rel="external">github</a><br>某乎较好的<a href="https://www.zhihu.com/question/41354392" target="_blank" rel="external">帖子</a><br>blog<a href="http://blog.csdn.net/chedan541300521/article/details/54895880" target="_blank" rel="external">地址</a><br>陈天奇<a href="http://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf" target="_blank" rel="external">slides</a><br>陈天奇<a href="https://arxiv.org/abs/1603.02754" target="_blank" rel="external">paper</a></p>
</blockquote>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍?"></a>原理介绍?</h1><p>基本的概念如tree, mart, residual等就不介绍了，直接进入主题，<code>xgboost</code>的目标函数:<br>                             $Obj(\theta) = L(\theta) + \Omega(\theta)$<br>$\theta$是我们要求的最优解，可以对应<code>xgboost</code>上各个<code>tree</code>上最有<code>split</code>和最有<code>leaf value</code>，$L$是残差，即模型预测值和实际训练样本的差值，当然是越小越好，$\Omega$是模型复杂度，这个也很重要，防止过拟合以及严重的抖动，一般模型需要做<code>bias</code>和<code>varience</code>的校验，一个对应$L$，一个对应$\Omega$。<code>xgboost</code>是<code>mart</code>，预测值是所有的<code>tree</code>的加权相加:<br>$\hat{y_i}=\sum_{i=1}^{K}f_k(x_i),f_k \in{\mathcal{F}}$<br>以上是mart建立之后如何预测，tree建立在分裂时，会有目标，<code>Objective</code>细化为<br>$Obj=\sum_{i=1}^{n} l(y_i, \hat{y_i})+\sum_{k=1}^{K} \Omega(f_i)<br>=\sum_{i=1}^{n}l(y_i, \hat y_i^{t-1} + f_t(x_i)) + \Omega(f_t) + constant $<br>$f_t$是第t轮迭代，即第t颗树，由于t轮之前的参数已经确定，所以最后归结为<code>constant</code>，目标也是寻找最优的$f_t$，让<code>Obj</code>最小。<br>使用二阶泰勒展开的方式<br>$f(x+\Delta{x}) \approx f(x) + f’(x)\Delta{x} + \frac{1}{2}f’’(x)\Delta{x^2}$<br>做一下转化:</p>
<blockquote>
<p>$l(y_i, \hat y_i^{t-1} + f_t(x_i)) =&gt; f(x+\Delta{x}) $<br>$g_i=\delta_{\hat y_i^{t-1}}{l(y_i, \hat{y}^{(t-1)})}$<br>$h_i=\delta_{\hat y_i^{t-1}}^2 {l(y_i, \hat{y}^{(t-1)})}$</p>
</blockquote>
<p>则<code>Obj</code>在t轮迭代的目标为<br>$Obj=\sum_{i=1}^{n}l(y_i, \hat y_i^{t-1} + f_t(x_i)) + \Omega(f_t) + constant<br>=\sum_{i=1}^{n}[l(y_i, \hat y_i^{t-1}) + g_if_t(x_i) + \frac{1}{2}h_if_t^2(x_i)] + \Omega(f_t) + constant$<br>模型复杂度$\Omega(f_t)$的定义：<br>$\Omega(f_t)=\gamma{T} + \frac{1}{2}\lambda\sum_{j=1}^{T}w_j{^2}$<br>$T$是叶子节点的个数，$w_j$是叶子节点对叶的<code>leaf_score</code>,进一步化简$Obj(f_t)$:<br>$Obj=\sum_{i=1}^{n}[g_if_t(x_i) + \frac{1}{2}h_if_t^2(x_i)] + \Omega(f_t)<br>=\sum_{i=1}^{n}[g_iw_{q(x_i)} + \frac{1}{2}h_iw^2_{q(x_i)}] + \gamma{T} + \frac{1}{2}\lambda\sum_{j=1}^{T}w_j{^2}$<br>$=\sum_{j=1}^{T}[(\sum_{i \in I_j}g_i)w_j + \frac{1}{2}(\sum_{i \in I_j}h_i + \lambda)w^2_j] + \gamma T$</p>
<p>这样终于看出GBDT计算收益的最终公式了：<br>$(1) w_j = - \frac{G_j}{H_j+\lambda}$<br>$(2) Obj =- \frac{1}{2}\sum_{j=1}^{T}\frac{G^2_j}{H_j + \lambda} + \gamma T$<br>$(3) Gain = \frac{1}{2}[\frac{G^2_L}{H_L+\lambda} + \frac{G^2_R}{H_R+\lambda} - \frac{(G_L + G_R)^2}{H_L + H_R + \lambda}] - \gamma$</p>
<p>$\gamma$就是<del>传说中的一阶正则项</del>，$\gamma$是后面提到的参数<code>min_split_loss</code>，剪枝使用，太小的收益不必分裂。树节点分裂的收益达到某个值后再分裂，而二阶正则项$\lambda$主要是为了防止过拟合, 增强模型的稳定性。</p>
<h1 id="如何并行化？"><a href="#如何并行化？" class="headerlink" title="如何并行化？"></a>如何并行化？</h1><p>xgboost相对于gbdt是有一个并行的优势，怎么并行的呢，下面会读数据并行化和树分裂时的并行化分两部分介绍</p>
<h2 id="读数据并行"><a href="#读数据并行" class="headerlink" title="读数据并行"></a>读数据并行</h2><p>开始的输入数据是libsvm格式，形如”1 1:1.2 2:2.1 3:3.5 …”一行一行的数据，训练集合可能会非常大，大家都知道xgboost会枚举所有的特征值，选用最佳分割，所以开始是需要按列把各个feature排序好，这一步在xgboost里是并行做的。。。xgboost使用DMatrix存储训练数据，每次训练前会调用InitColAccess()将行训练数据支持按列取的数据，这里是通过MakeOneBatch多线程来实现的，这么多列属性的排序被n个线程平分，最后将数据转化成 key,value的方式，key是列id，value是rowid, val的pair，rowid是该列所对应的行编号，用于拿出整行训练数据的信息，val是该行该列下的具体数字，这个信息最后会存入DMatrix的SparsePage中，可知道最后是存了feature_num个实际train_set，用于训练阶段方便的取数据，不用做重复的排序工作了。</p>
<h2 id="分裂选择并行化"><a href="#分裂选择并行化" class="headerlink" title="分裂选择并行化"></a>分裂选择并行化</h2><p>tree进行分裂的时候会考量每个feature的每个value，如果串行计算，肯定会比较慢，xgboost使用了并行化，多个线程综合考虑每个列的情况，主要在FindSplit()里做的<br>● this-&gt;UpdateSolution(iter-&gt;Value(), gpair, *p_fmat); 主函数，枚举每一个feature，的每一个value，尝试收益<br>● this-&gt;SyncBestSolution(qexpand); 多线程merger，当前node的最好的split<br>● sync solution; 同步成果，给tree建node，左右儿子等<br>每个线程会枚举自己的feature的各个split value，将最佳分裂保存到当前线程的结构中，最后所有的线程会根据各自的best split做merge，从而找到当前tree的最佳分裂，这里也用到了并行化，共享了读数据阶段产生的SparsePage</p>
<p>这些并行化和共享让xgboost的训练速度非常快。以上基本上解决了我开始的三个疑问，下面说一些xgboost的细节。</p>
<h2 id="细节1-tree如何维护当前的数据集？"><a href="#细节1-tree如何维护当前的数据集？" class="headerlink" title="细节1: tree如何维护当前的数据集？"></a>细节1: tree如何维护当前的数据集？</h2><p>这个是通过postion这个vector来实现的，vector是训练机的大小，每个值代表当前训练样本属于的树节点编号，开始都是0，即开始所有的样本都是在根节点上。expand这个vector保存当前叶子节点，即即将开始下一轮分裂的叶子节点编号，当然开始也是初始化为0，postion里的所有值都是取自于expand</p>
<h2 id="细节2-模型复杂度"><a href="#细节2-模型复杂度" class="headerlink" title="细节2: 模型复杂度"></a>细节2: 模型复杂度</h2><p>主要说下$\gamma,\alpha, \lambda$这三个，这三个控制这模型复杂度。</p>
<ul>
<li>$\gamma$是<code>min_split_loss</code>，控制树的分裂深度，收益必须大于该值才分裂。</li>
<li><p>$\alpha$是一阶正则项，也是控制复杂度的，不过比较弱，一般训练设置为0，控制这Grad(一阶梯度)不至于过大或者过小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">if (p.reg_alpha == 0.0f) &#123;</div><div class="line">	return Sqr(sum_grad) / (sum_hess + p.reg_lambda);</div><div class="line">&#125; else &#123;</div><div class="line">	return Sqr(ThresholdL1(sum_grad, p.reg_alpha)) /</div><div class="line">		(sum_hess + p.reg_lambda);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>$\lambda$是二阶正则项，具体使用上面的推到也已经明了了</p>
</li>
</ul>
<h1 id="Lambda-Object"><a href="#Lambda-Object" class="headerlink" title="Lambda Object"></a>Lambda Object</h1><p>非常重要的应用，相对于<code>gbdt</code>，或许这个才算是最重要的区别，即可以自定义目标函数(loss)，传统的<code>Objective loss</code>即预测值和标签值的差异，在实际工程中的应用显然是不够的，很多指标有实际的公式，如果表示成残差，梯度，这个活就交给<code>lambda</code>来做了，如下要素:<br>● 组的概念<br>● 选择两个组内两个标签不同的一对<br>● $P_{ij} = \frac{1}{1+e^{-\sigma(s_i-s_j)}}$<br>● $C = -\bar P_{ij} log P_{ij} - (1 - \bar P_{ij})log(1 - P_{ij})$<br>● $C=log(1+e^{-\sigma(s_i-s_j)})$<br>● $\delta{w_k} = -\eta\sum_i\lambda_{i}\frac{\partial s_i}{\partial w_k}$<br>● $\lambda_i = \sum_{j:{i, j}\in I} \lambda_{ij} - \sum_{j:{j, i}\in I} \lambda_{ij}$<br>● $\lambda_{ij} = \frac{\partial C(s_i - s_j)}{\partial{s_i}} = \frac{-\sigma}{1+e^{\sigma(s_i-s_j)}} * \Delta$</p>
<p>这样，成功的讲工程上的知道公式产生的残差计算成功的引入到了梯度中去,$\Delta$可以是<code>NDCG</code>以及<code>MAP</code>等等。如何从<code>pointwise</code>的思路转到<code>pairwise listwise</code>，$\lambda$的应用是关键，其中的转化思路如上面的推理所示，具体代码在<code>src/objective/rank_obj.cc</code>中，定义了基本的类<code>LambdaRankObj</code>，在此基础上实现了<code>PairwiseRankObj</code>和<code>LambdaRankObjNDCG</code>以及<code>LambdaRankObjMAP</code>等。<code>LambdaRankObj</code>主要的函数就是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">void GetGradient(const std::vector&lt;bst_float&gt;&amp; preds,</div><div class="line">	const MetaInfo&amp; info,</div><div class="line">	int iter,</div><div class="line">	std::vector&lt;bst_gpair&gt;* out_gpair)</div><div class="line">preds: 当前预测值(fx)</div><div class="line">info: 样本信息</div><div class="line">iter: 当前迭代轮数(随机种子)</div><div class="line">out_gpair: 生成的一阶梯度、二阶梯度存放地</div></pre></td></tr></table></figure></p>
<p>该函数的流程如下</p>
<ul>
<li>遍历group</li>
<li>组内排序，按预测值放入lst, 按照标签值放入rec</li>
<li>rec内按照不同的标签组成pairs, 采用uniform_int_distribution的方式组</li>
<li>调用GetLambdaWeight获取$\Delta$, pairwise的什么也没干，默认是1</li>
<li>根据预测值和标签，算Sigmod值，然后乘$\Delta$, 算出的g,h分别放入 out_gpair 的 i, j中，i &gt; j, 一个是加，一个是减<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">gpair[pos.rindex].grad += g * w;</div><div class="line">gpair[pos.rindex].hess += 2.0f * w * h;</div><div class="line">gpair[neg.rindex].grad -= g * w;</div><div class="line">gpair[neg.rindex].hess += 2.0f * w * h;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>NDCG的GetLambdaWeight怎么算？这里就引入了计算公式。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">void GetLambdaWeight(const std::vector&lt;ListEntry&gt; &amp;sorted_list,</div><div class="line">                     std::vector&lt;LambdaPair&gt; *io_pairs) override</div><div class="line">sorted_list:按照预测值排的序</div><div class="line">io_pairs:抽出的pairs</div></pre></td></tr></table></figure></p>
<p>计算流程：</p>
<ul>
<li>按照labels，算出最大的maxNDCG作为分母</li>
<li>算original ndcg以及交换之后的ndcg，做差值，处maxNDCG</li>
</ul>
<h2 id="问题1-如何做到好的结果按照NDCG更快排上去的"><a href="#问题1-如何做到好的结果按照NDCG更快排上去的" class="headerlink" title="问题1:如何做到好的结果按照NDCG更快排上去的?"></a>问题1:如何做到好的结果按照NDCG更快排上去的?</h2><p>好的结果产生的$\Delta$在NDCG计算时会更大，weight会更高，所以获得加权会更高</p>
<h2 id="问题2-好的结果每次都会加权，最后预测值会很大？"><a href="#问题2-好的结果每次都会加权，最后预测值会很大？" class="headerlink" title="问题2:好的结果每次都会加权，最后预测值会很大？"></a>问题2:好的结果每次都会加权，最后预测值会很大？</h2><p>不会的, 如果好的记过得到的score很高了，即$s_i$很高，会拉开与其他结果($s_j$)的差距，所以系数$\frac{-\sigma}{1+e^{\sigma(s_i-s_j)}}$会很小，这个系数表示目前模型的好坏，如果很好了即使$\Delta$很大也是没有多少梯度的</p>
<h1 id="应用参数"><a href="#应用参数" class="headerlink" title="应用参数"></a>应用参数</h1><p>首先推荐官方的API，这个没有更权威的了，如果使用，一定要仔细阅读，我是在python中使用，所以会看<a href="http://xgboost.readthedocs.io/en/latest/python/python_api.html" target="_blank" rel="external">python的API</a>)。首先说一下命令行版本也就是github拉下来之后直接编译出的二进制，直接使用”./xgboost config.ini”的方式即可，注意配置的格式，其实参考”src/cli_main.cc”也可以大概看出需要配置那些参数，我贴一下自己的训练配置和预测配置:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">● train.conf</div><div class="line">train_path=/Users/wang/company/ltr/ask.train</div><div class="line">model_out=/Users/wang/company/ltr/module.out.1</div><div class="line">objective=rank:ndcg</div><div class="line">num_round=200</div><div class="line">eval_metric=ndcg@3-</div><div class="line">task=train</div><div class="line">eval_train=true</div><div class="line">max_depth=4</div><div class="line">min_split_loss=0.2</div><div class="line">reg_lambda=2.0</div><div class="line"></div><div class="line">● test.conf</div><div class="line">test_path=feature.ask</div><div class="line">name_pred=pred.txt</div><div class="line">model_in=module.out</div><div class="line">objective=rank:ndcg</div><div class="line">task=pred</div></pre></td></tr></table></figure></p>
<p>源码中是使用<a href="https://github.com/dmlc/dmlc-core" target="_blank" rel="external">dmlc-core</a>来做的参数处理，十分方便，我是做搜索排序相关，所以目标使用<code>ndcg, reg_lambda</code>对应上面所说的$\lambda$，<code>min_split_loss</code>是树分裂所达到的最小收益值，即上面公式(3)中的Gain，一阶正则项$\alpha＝0$。<br>不过还是推荐使用python版本，python版本在训练时，可以看到每轮之后test集的准确度(ndcg值)，可以直观的看到效果，主要是param的设置，如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># param</div><div class="line">param = &#123;&apos;eval_metric&apos;: &apos;ndcg@3-&apos;, &apos;base_score&apos;: 0.0, &apos;max_leaves&apos;: 10, &apos;alpha&apos;: 0.0, &apos;tree_method&apos;: &apos;exact&apos;, &apos;bagging&apos;: 3, &apos;silent&apos;: 1, &apos;grow_policy&apos;: &apos;depthwise&apos;, &apos;subsample&apos;: 1.0, &apos;eta&apos;: 0.2, &apos;max_bin&apos;: 256, &apos;objective&apos;: &apos;rank:ndcg&apos;, &apos;max_depth&apos;: 4, &apos;gamma&apos;: 0.2, &apos;lambda&apos;: 2.0&#125;</div><div class="line"></div><div class="line">#设置测试集合的train</div><div class="line">num_round = 200</div><div class="line">dtrain.set_group(numpy.loadtxt(&apos;../../company/ltr/ask.train.group&apos;, dtype=numpy.int32))</div><div class="line">dtest.set_group(numpy.loadtxt(&apos;../../company/ltr/ask.test.group&apos;, dtype=numpy.int32))</div><div class="line">bst = xgb.train(param, dtrain, num_round, [(dtrain, &apos;train&apos;), (dtest, &apos;test&apos;)])</div></pre></td></tr></table></figure></p>
<p>最后贴一张训练截图<br><img src="/images/xgboost_ndcg.jpg" alt="ndcg"></p>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    Last updated: <time datetime="2017-06-14T11:51:06.000Z" itemprop="dateUpdated">2017-06-14 19:51:06</time>
</span><br>


        
        这里可以写作者留言，标签和 hexo 中所有变量及辅助函数等均可调用，示例：<a href="/2017/02/15/Xgboost/" target="_blank" rel="external">http://yoursite.com/2017/02/15/Xgboost/</a>
        
    </div>
    
    <footer>
        <a href="http://yoursite.com">
            <img src="/img/avatar.jpg" alt="ustcJin">
            ustcJin
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/it/">it</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ml/">ml</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2017/02/15/Xgboost/&title=《Xgboost源码阅读》 — Hexo&pic=http://yoursite.com/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2017/02/15/Xgboost/&title=《Xgboost源码阅读》 — Hexo&source=" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2017/02/15/Xgboost/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Xgboost源码阅读》 — Hexo&url=http://yoursite.com/2017/02/15/Xgboost/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2017/02/15/Xgboost/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2017/03/08/qa-cnn/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">CNN在问答领域识别中应用</h4>
      </a>
    </div>
  

  
</nav>



    




















</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        谢谢大爷~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/img/wechat.jpg" data-alipay="/img/alipay.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>This blog is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</span>
        </p>
    </div>
    <div class="bottom">
        <p><span>ustcJin &copy; 2015 - 2020</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2017/02/15/Xgboost/&title=《Xgboost源码阅读》 — Hexo&pic=http://yoursite.com/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2017/02/15/Xgboost/&title=《Xgboost源码阅读》 — Hexo&source=" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2017/02/15/Xgboost/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Xgboost源码阅读》 — Hexo&url=http://yoursite.com/2017/02/15/Xgboost/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2017/02/15/Xgboost/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAAAAACKZ2kyAAABwklEQVR42u3aS4rDMBAFwNz/0hmY1cAQuZ9akh0orUxs5HIWjfrzepXX+3eN7/595v/1+JfFCxcXt819D9cnbv1u+kmfDLi4uOe54+AVbDckVugXNlxc3Idx584hlT1xcXG/l5smOfWEChcX95ncSvKTpkZjxPZcDRcXt8HtBJ1V1xvru7i4uCH3Ha61rZH47bi4uEe49UZIJQWqHGsqydVFmMPFxd3MrYSeFFdvsdQDHC4u7kluJ6ykgxRp4TWo8uLi4i7l1jeqgzotk4uEChcX9yA3bXamBZQ0ifr4Gbi4uMe59aGKfqm0XjyNvxIXF3cpd64hOjeukRZKcHFx7+LOtVc7f0E97Yl7wri4uEu5nYNIMEKBi4v7hdw6ot5Wqd+9aKXg4uJu5qYNlXQgo9KaTQ9MuLi4u7mVwLHqWNMf18DFxT3JrQ9idsqsc00XXFzcu7g7yqb1Ia1gN1xc3CPcudfUEemwVzroiYuLu4/bT13ipkh5dAMXF/debhqe5p5vJT+4uLiP5Laao40xjld9U1xc3Fu59WNK2pTFxcV9DrfzgjRspaWQyVwNFxe3wZ1rgYxTlPQANFdyxcXF3cD9AXaPi7KaOXEAAAAAAElFTkSuQmCC" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>






<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = '死鬼去哪里了！';
            clearTimeout(titleTime);
        } else {
            document.title = '(つェ⊂)咦!又好了!';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



</body>
</html>
