<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>CNN在问答领域识别中应用 | Hexo</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="it,ml">
    <meta name="description" content="背景短文本question-answer匹配度识别问题，论文(Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks.pdf), github实现。github的作者基本上实现了文章里的算法，计算的精度也差不多，不过使用theano实现的，我准备使用tensorflow实现，并解决大规模预料训练太慢的问题。">
<meta property="og:type" content="article">
<meta property="og:title" content="CNN在问答领域识别中应用">
<meta property="og:url" content="http://yoursite.com/2017/03/08/qa-cnn/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="背景短文本question-answer匹配度识别问题，论文(Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks.pdf), github实现。github的作者基本上实现了文章里的算法，计算的精度也差不多，不过使用theano实现的，我准备使用tensorflow实现，并解决大规模预料训练太慢的问题。">
<meta property="og:image" content="http://yoursite.com/images/deep_qa.jpg">
<meta property="og:updated_time" content="2018-03-03T04:49:39.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CNN在问答领域识别中应用">
<meta name="twitter:description" content="背景短文本question-answer匹配度识别问题，论文(Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks.pdf), github实现。github的作者基本上实现了文章里的算法，计算的精度也差不多，不过使用theano实现的，我准备使用tensorflow实现，并解决大规模预料训练太慢的问题。">
<meta name="twitter:image" content="http://yoursite.com/images/deep_qa.jpg">
    
        <link rel="alternate" type="application/atom+xml" title="Hexo" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">ustcJin</h5>
          <a href="mailto:452697589@qq.com" title="452697589@qq.com" class="mail">452697589@qq.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/yscoder" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="http://www.weibo.com/ysweb" target="_blank" >
                <i class="icon icon-lg icon-weibo"></i>
                Weibo
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/custom"  >
                <i class="icon icon-lg icon-link"></i>
                测试
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">CNN在问答领域识别中应用</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">CNN在问答领域识别中应用</h1>
        <h5 class="subtitle">
            
                <time datetime="2017-03-08T10:51:28.000Z" itemprop="datePublished" class="page-time">
  2017-03-08
</time>


            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#背景"><span class="post-toc-number">1.</span> <span class="post-toc-text">背景</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#架构？"><span class="post-toc-number">2.</span> <span class="post-toc-text">架构？</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#使用theano的实现"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">使用theano的实现</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#数据预处理-embedding"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">数据预处理(embedding)</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Load"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">Load</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#词向量转化"><span class="post-toc-number">2.4.</span> <span class="post-toc-text">词向量转化</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#卷积"><span class="post-toc-number">2.5.</span> <span class="post-toc-text">卷积</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Activation-tanh"><span class="post-toc-number">2.6.</span> <span class="post-toc-text">Activation (tanh)</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Pooling"><span class="post-toc-number">3.</span> <span class="post-toc-text">Pooling</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#PairwiseNoFeatsLayer"><span class="post-toc-number">4.</span> <span class="post-toc-text">PairwiseNoFeatsLayer</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#LinearLayer"><span class="post-toc-number">5.</span> <span class="post-toc-text">LinearLayer</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#LogisticRegression"><span class="post-toc-number">6.</span> <span class="post-toc-text">LogisticRegression</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#训练网络"><span class="post-toc-number">7.</span> <span class="post-toc-text">训练网络</span></a></li></ol>
        </nav>
    </aside>


<article id="post-qa-cnn"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">CNN在问答领域识别中应用</h1>
        <div class="post-meta">
            <time class="post-time" title="2017-03-08 18:51:28" datetime="2017-03-08T10:51:28.000Z"  itemprop="datePublished">2017-03-08</time>

            


            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>短文本question-answer匹配度识别问题，论文(Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks.pdf), github<a href="https://github.com/aseveryn/deep-qa" target="_blank" rel="external">实现</a>。github的作者基本上实现了文章里的算法，计算的精度也差不多，不过使用theano实现的，我准备使用tensorflow实现，并解决大规模预料训练太慢的问题。当然本文要开始从分析git的实现开始讲起，会穿插theano的一些语法，实现等，我自己也是从零学起的，且当给自己留个笔记吧。</p>
<h1 id="架构？"><a href="#架构？" class="headerlink" title="架构？"></a>架构？</h1><p>不能不提到的论文中经典的架构图。<br><img src="/images/deep_qa.jpg" alt=""><br>网络用文字梳理的结果如下:</p>
<ol>
<li>question answer并行处理成词向量</li>
<li>词向量与卷积核做运算得到n个len(q or a)维的向量</li>
<li>对2中得到的向量做Activation和Pooling处理，得到1维数组，大小为n</li>
<li>问题和答案抽出的1维数组分别与相似度矩阵M做乘积预算，得到相似度，即 $A*M*Q=sim$</li>
<li>计算answer和question中的相同部分F，将A,sim,Q,F拼接成新的向量</li>
<li>将5中得到的向量做线性变化，即 $\alpha(W*X+b)$</li>
<li>最后使用Softmax对6中得到的linear之后的向量做分类</li>
</ol>
<h2 id="使用theano的实现"><a href="#使用theano的实现" class="headerlink" title="使用theano的实现"></a>使用theano的实现</h2><p>作者的实现有一些改动，如第5步骤中计算得到的交叉部分F，这部分可以是交叉词的词向量，也可以是交叉词的idf，比重等，显然idf和比重更容易让人信服，不过这个值不好处理，作者并没有用，而是直接使用的交叉词的词向量拼到question和answer的词向量中，即将这部分直接放到开头做了。</p>
<h2 id="数据预处理-embedding"><a href="#数据预处理-embedding" class="headerlink" title="数据预处理(embedding)"></a>数据预处理(embedding)</h2><p>这部分主要是将question-answer对分词(英文就是空格直接分词), 然后根据word2vec，将问题和答案分解成word2vec的词向量，并收集全集词表，word2vec缺失的词使用默认值填充。难点在于训练集合的选取，这是有监督的学习，对于中文的海量语法来说，需要的训练集合的规模也是非常大的。</p>
<h2 id="Load"><a href="#Load" class="headerlink" title="Load"></a>Load</h2><p>主要load的数据有train, dev, test三类，train是训练参数使用，dev是验证参数，test是实测使用，其实dev和test可以归为一类，每类数据分为question, answer, overlap。</p>
<h2 id="词向量转化"><a href="#词向量转化" class="headerlink" title="词向量转化"></a>词向量转化</h2><p>LookupTableFast将question, answer, overlap转化为词向量。这里会讲pad部分(即卷积的宽度补上)，最后输出的是 [batch_size, 1, 2 * (q_size + q_filter_widths - 1), ndim], ndim是词向量的宽度(word2vec生成的词向量的size)，后面ndim的长度会拓展为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># sentence长度 + 交叉长度</div><div class="line">ndim = vocab_emb.shape[1] + vocab_emb_overlap.shape[1]</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">class LookupTableFastStatic(Layer):</div><div class="line">	def __init__(self, W=None, pad=None):</div><div class="line">		super(LookupTableFastStatic, self).__init__()</div><div class="line">		self.pad = pad</div><div class="line">		self.W = theano.shared(value=W, name=&apos;W_emb&apos;, borrow=True)</div><div class="line"></div><div class="line">		def output_func(self, input):</div><div class="line">			out = self.W[input.flatten()].reshape((input.shape[0], 1, input.shape[1], self.W.shape[1]))</div><div class="line">			if self.pad:</div><div class="line">				pad_matrix = T.zeros((out.shape[0], out.shape[1], self.pad, out.shape[3]))</div><div class="line">	  			out = T.concatenate([pad_matrix, out, pad_matrix], axis=2)</div><div class="line">	  		return out</div><div class="line"></div><div class="line">	  def __repr__(self):</div><div class="line">		  return &quot;&#123;&#125;: &#123;&#125;&quot;.format(self.__class__.__name__, self.W.shape.eval())</div></pre></td></tr></table></figure>
<h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p>定义Conv2dLayer来做卷积类使用，卷积的初始化如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">def __init__(self, rng, filter_shape, input_shape=None, W=None):</div><div class="line"># @rng: 初始化种子</div><div class="line"># @filter_shape: 卷积核的样式，filter_shape = (nkernels, num_input_channels, filter_width, ndim), nkernels = 100, num_input_channels = 1, 可见与question长度无关。</div><div class="line"># @input_shape: 同上一层词向量层的输出</div><div class="line"># @self.W 也和filter_shape具有相同的shape，随机化一些数字</div></pre></td></tr></table></figure></p>
<p>卷积使用库函数，调用如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">def output_func(self, input):</div><div class="line">	return conv.conv2d(input, self.W, border_mode=&apos;valid&apos;,</div><div class="line">			filter_shape=self.filter_shape,</div><div class="line">			image_shape=self.input_shape)</div></pre></td></tr></table></figure></p>
<p>看看<code>conv2d</code>函数的返回, 看到output的是 [batch_size, filter_size, sentence_size, ndim]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Parameters:	</div><div class="line">input (dmatrix of dtensor3) – Symbolic variable for images to be filtered.</div><div class="line">filters (dmatrix of dtensor3) – Symbolic variable containing filter values.</div><div class="line">border_mode (&#123;&apos;valid&apos;, &apos;full&apos;&#125;) – See scipy.signal.convolve2d.</div><div class="line">subsample – Factor by which to subsample output.</div><div class="line">image_shape (tuple of length 2 or 3) – ([number images,] image height, image width).</div><div class="line">filter_shape (tuple of length 2 or 3) – ([number filters,] filter height, filter width).</div><div class="line">kwargs – See theano.tensor.nnet.conv.conv2d.</div><div class="line">Returns:	</div><div class="line">Tensor of filtered images, with shape ([number images,] [number filters,] image height, image width)</div></pre></td></tr></table></figure></p>
<p><strong>何为卷积？如何卷积?</strong><br>卷积为分时加权，在词向量上表现为分段计算作为权重，粒度更细了，input_shape细化为单个qa，即为如下格式(加上filter_width)。引用某乎上对卷积的解释:</p>
<blockquote>
<p>cnn的核心在于卷积核，其实关于卷积核还有另一个名字叫做滤波器，从信号处理的角度而言，滤波器是对信号做频率筛选，这里主要是空间-频率的转换，cnn的训练就是找到最好的滤波器使得滤波后的信号更容易分类，还可以从模版匹配的角度看卷积，每个卷积核都可以看成一个特征模版，训练就是为了找到最适合分类的特征模板。</p>
</blockquote>
<p>卷积核最后是作为最终的feature，每个卷积核作为一个特征，与question、answer等都无关了，所以卷积核的特征采集是非常重要的。</p>
<p>$$<br>S =<br>\begin{vmatrix}<br>|    &amp; |    &amp;    …    &amp; | &amp; | \\<br>filter &amp; w_1 &amp; … &amp; w_{|s|} &amp; filter \\<br>|    &amp; |    &amp;    …    &amp; | &amp; | \\<br>\end{vmatrix}<br>$$<br>$S.shape = [ndim, 2 \cdot (filter - 1) + len(s)]$<br>卷积核为[dim, m]维度，卷积公式如下:<br>$c_i=S \cdot f=S^T_{[i:i+m-1]} \cdot f=\sum_{k=i}^{i+m-1} s_kf_k$<br>注意是S的转置矩阵与f的相乘, 最后得到的是$[2 \cdot filter + |s|]$的宽度数组，即为卷积结果。增加filter_width是为了让S的每个word享受到相同的卷积效果。</p>
<h2 id="Activation-tanh"><a href="#Activation-tanh" class="headerlink" title="Activation (tanh)"></a>Activation (tanh)</h2><p>使用nn_layers.NonLinearityLayer作为主类，初始化以及output函数:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">NonLinearityLayer(b_size=filter_shape[0], activation=activation)</div><div class="line"></div><div class="line">def output_func(self, input):</div><div class="line">	return self.activation(input + self.b.dimshuffle(&apos;x&apos;, 0, &apos;x&apos;, &apos;x&apos;))</div></pre></td></tr></table></figure></p>
<p>dimshuffle是将b拓展到4维，正好与卷积的output匹配相加。这里有一个问题，卷积出的第四维度是ndim，和公式算的$c_i$没有该维度，该维度上直接相加了。</p>
<h1 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># 在第二维度上，即image height，也就是sentence</div><div class="line">def max_pooling(input):</div><div class="line">  return T.max(input, axis=2)</div></pre></td></tr></table></figure>
<h1 id="PairwiseNoFeatsLayer"><a href="#PairwiseNoFeatsLayer" class="headerlink" title="PairwiseNoFeatsLayer"></a>PairwiseNoFeatsLayer</h1><p>这个是将q和a经过上面一系列的层产生的结果(最后是经过Pooling处理得到的[batch_size, n])做乘积，求q和a的相似性sim，最后将q,a,sim拼接。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># 注意这里的参数W矩阵是(n * n)的</div><div class="line">def output_func(self, input):</div><div class="line">	# P(Y|X) = softmax(W.X + b)</div><div class="line">	q, a = input[0], input[1]</div><div class="line">	# dot = T.batched_dot(q, T.batched_dot(a, self.W))</div><div class="line">	dot = T.batched_dot(q, T.dot(a, self.W.T))</div><div class="line">	out = T.concatenate([dot.dimshuffle(0, &apos;x&apos;), q, a], axis=1)</div><div class="line">	return out</div></pre></td></tr></table></figure></p>
<p>out的长度为<code>q_logistic_n_in + a_logistic_n_in + 1</code></p>
<h1 id="LinearLayer"><a href="#LinearLayer" class="headerlink" title="LinearLayer"></a>LinearLayer</h1><p>线性变换，这里的输入是长度为<code>q_logistic_n_in + a_logistic_n_in + 1</code>的特征数组，需要经过线性变化，LinearLayer<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># W是(q_logistic_n_in + a_logistic_n_in + 1) * (q_logistic_n_in + a_logistic_n_in + 1)</div><div class="line">def output_func(self, input):</div><div class="line">    return self.activation(T.dot(input, self.W) + self.b)</div></pre></td></tr></table></figure></p>
<h1 id="LogisticRegression"><a href="#LogisticRegression" class="headerlink" title="LogisticRegression"></a>LogisticRegression</h1><p>最后一步，上面的输入仍然是<code>q_logistic_n_in  + a_logistic_n_in + 1</code>, 使用<code>softmax</code>输出求解，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">def output_func(self, input):</div><div class="line">	# P(Y|X) = softmax(W.X + b)</div><div class="line">	self.p_y_given_x = T.nnet.softmax(self._dot(input, self.W) + self.b)</div><div class="line">	self.y_pred = T.argmax(self.p_y_given_x, axis=1)</div><div class="line">	return self.y_pred</div></pre></td></tr></table></figure></p>
<p>注意<code>T.argmax</code>是获取下标，所以这里的输出是直接分类(本问题中是0,1), p_y_given_x是给的具体的概率值。</p>
<h1 id="训练网络"><a href="#训练网络" class="headerlink" title="训练网络"></a>训练网络</h1><p>前面的整个网络已经布局完毕，是计算<code>loss</code>的时候了，cost=negative_log_likelihood(y)=-T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y]), 使用adadelta训练参数，这个cost如何理解呢？找到了解释，我自己是没有跑通，囧。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"># y.shape[0] is (symbolically) the number of rows in y, i.e.,</div><div class="line"># number of examples (call it n) in the minibatch</div><div class="line"># T.arange(y.shape[0]) is a symbolic vector which will contain</div><div class="line"># [0,1,2,... n-1] T.log(self.p_y_given_x) is a matrix of</div><div class="line"># Log-Probabilities (call it LP) with one row per example and</div><div class="line"># one column per class LP[T.arange(y.shape[0]),y] is a vector</div><div class="line"># v containing [LP[0,y[0]], LP[1,y[1]], LP[2,y[2]], ...,</div><div class="line"># LP[n-1,y[n-1]]] and T.mean(LP[T.arange(y.shape[0]),y]) is</div><div class="line"># the mean (across minibatch examples) of the elements in v,</div><div class="line"># i.e., the mean log-likelihood across the minibatch.</div><div class="line">return -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y])</div></pre></td></tr></table></figure></p>
<p>如何更新参数呢？<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">updates = sgd_trainer.get_adadelta_updates(cost, params, rho=0.95, eps=1e-6, max_norm=max_norm, word_vec_name=&apos;W_emb&apos;)</div></pre></td></tr></table></figure></p>
<p>作者实现的adadelta算法如下所示, 加上了我自己的理解和注释，我感觉这块的实现有些问题，因为adadelta是前t次的迭代，而这里的和显然是从开始到结束，有点像adagrad。后面贴的链接是几种求参迭代的方法。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">def get_adadelta_updates(cost, params, rho=0.95, eps=1e-6, max_norm=9, word_vec_name=&apos;W_emb&apos;):</div><div class="line">	print &quot;Generating adadelta updates&quot;</div><div class="line">	updates = OrderedDict(&#123;&#125;)</div><div class="line">	exp_sqr_grads = OrderedDict(&#123;&#125;)</div><div class="line">	exp_sqr_ups = OrderedDict(&#123;&#125;)</div><div class="line">	gparams = []</div><div class="line">	# 这里设置了三个变量, for every param：</div><div class="line">	# exp_sqr_grads init zeros</div><div class="line">	# exp_sqr_ups zeros</div><div class="line">	# gparams [] list append gp(grad)</div><div class="line">	for param in params:</div><div class="line">		exp_sqr_grads[param] = build_shared_zeros(param.shape.eval(), name=&quot;exp_grad_%s&quot; % param.name)</div><div class="line">		print &apos;cost &apos;, cost</div><div class="line">		print &apos;param.shape.eval&apos;, param.shape.eval()</div><div class="line">		gp = T.grad(cost, param)</div><div class="line">		print &apos;gp&apos;, gp</div><div class="line">		exp_sqr_ups[param] = build_shared_zeros(param.shape.eval(), name=&quot;exp_grad_%s&quot; % param.name)</div><div class="line">		print &apos;exp_sqr_ups&apos;, exp_sqr_ups[param].shape</div><div class="line">		gparams.append(gp)</div><div class="line">		print param, gp</div><div class="line">	#真正的计算, for every param</div><div class="line">	# exp_sg 之前的 sum(sqr(gp) 1...t-1) for now param</div><div class="line">	# exp_su 之前的 sum(step 1...t-1) for now param</div><div class="line">	# up_exp_sg = rho * exp_sg + (1 - rho) * T.sqr(gp); 加上现在的gp平方</div><div class="line">	# updates[exp_sg] = up_exp_sg 换上</div><div class="line">	# step =  -(T.sqrt(exp_su + eps) / T.sqrt(up_exp_sg + eps)) * gp,该次更新的param step,</div><div class="line">	  注意这里分母的gp是1..t，而分子的sum(step)是 1...t-1</div><div class="line">	#updates[exp_su] = rho * exp_su + (1 - rho) * T.sqr(step); 更新本次</div><div class="line">	#stepped_param = param + step;最后目标</div><div class="line">	for param, gp in zip(params, gparams):</div><div class="line">		exp_sg = exp_sqr_grads[param]</div><div class="line">		exp_su = exp_sqr_ups[param]</div><div class="line">	 	up_exp_sg = rho * exp_sg + (1 - rho) * T.sqr(gp)</div><div class="line">	 	updates[exp_sg] = up_exp_sg</div><div class="line">		step =  -(T.sqrt(exp_su + eps) / T.sqrt(up_exp_sg + eps)) * gp</div><div class="line">	 	updates[exp_su] = rho * exp_su + (1 - rho) * T.sqr(step)</div><div class="line">	 	stepped_param = param + step</div><div class="line">		# if (param.get_value(borrow=True).ndim == 2) and (param.name != word_vec_name):</div><div class="line">	 	if max_norm and param.name != word_vec_name:</div><div class="line">			col_norms = T.sqrt(T.sum(T.sqr(stepped_param), axis=0))</div><div class="line">			desired_norms = T.clip(col_norms, 0, T.sqrt(max_norm))</div><div class="line">			scale = desired_norms / (1e-7 + col_norms)</div><div class="line">			updates[param] = stepped_param * scale</div><div class="line">		else:</div><div class="line">			updates[param] = stepped_param</div><div class="line">	return updates</div></pre></td></tr></table></figure></p>
<p>参考资料:<br><a href="http://blog.csdn.net/luo123n/article/details/48239963" target="_blank" rel="external">http://blog.csdn.net/luo123n/article/details/48239963</a><br><a href="http://sebastianruder.com/optimizing-gradient-descent/index.html#gradientdescentvariants" target="_blank" rel="external">http://sebastianruder.com/optimizing-gradient-descent/index.html#gradientdescentvariants</a><br><a href="http://www.cnblogs.com/neopenx/p/4768388.html" target="_blank" rel="external">http://www.cnblogs.com/neopenx/p/4768388.html</a><br><a href="http://deeplearning.net/tutorial/code/lstm.py" target="_blank" rel="external">http://deeplearning.net/tutorial/code/lstm.py</a></p>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    Last updated: <time datetime="2018-03-03T04:49:39.000Z" itemprop="dateUpdated">2018-03-03 12:49:39</time>
</span><br>


        
        这里可以写作者留言，标签和 hexo 中所有变量及辅助函数等均可调用，示例：<a href="/2017/03/08/qa-cnn/" target="_blank" rel="external">http://yoursite.com/2017/03/08/qa-cnn/</a>
        
    </div>
    
    <footer>
        <a href="http://yoursite.com">
            <img src="/img/avatar.jpg" alt="ustcJin">
            ustcJin
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/it/">it</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ml/">ml</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2017/03/08/qa-cnn/&title=《CNN在问答领域识别中应用》 — Hexo&pic=http://yoursite.com/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2017/03/08/qa-cnn/&title=《CNN在问答领域识别中应用》 — Hexo&source=" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2017/03/08/qa-cnn/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《CNN在问答领域识别中应用》 — Hexo&url=http://yoursite.com/2017/03/08/qa-cnn/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2017/03/08/qa-cnn/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2017/03/20/base-dt/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">基本的决策树算法总结</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2017/02/15/Xgboost/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">Xgboost源码阅读</h4>
      </a>
    </div>
  
</nav>



    




















</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        谢谢大爷~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/img/wechat.jpg" data-alipay="/img/alipay.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>This blog is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</span>
        </p>
    </div>
    <div class="bottom">
        <p><span>ustcJin &copy; 2015 - 2020</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2017/03/08/qa-cnn/&title=《CNN在问答领域识别中应用》 — Hexo&pic=http://yoursite.com/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2017/03/08/qa-cnn/&title=《CNN在问答领域识别中应用》 — Hexo&source=" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2017/03/08/qa-cnn/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《CNN在问答领域识别中应用》 — Hexo&url=http://yoursite.com/2017/03/08/qa-cnn/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2017/03/08/qa-cnn/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAAAAACKZ2kyAAABxUlEQVR42u3aQW7DMAwEwPz/0ynQa2B3KUp0CoxPQWIr48uCFPV6xdf79/r8fHXn5/3332y+cHFx29z37XVFvPr1foX8qctXwsXFHeQm4bX2Glf3JOGIi4v7/dyk3LmPoXwdXFzc/8JNom1vQ4WLi/ssN2l+8gbp/jXW1sfFxZ3kdkJn1+eh/V1cXNz2VKLaxuSbHYv/jouLO8JNNj37bdLa1urlq+Li4h7m5u1H3pYkTUs14HBxcZ/irm2D9o9Z5OMZXFzcSW7S5PTbmKRI+qNUwsXFHeHm5cVaMCW4/DAHLi7uDDcvYtaOUOTDksI0GBcX9zC3E0x5tPU3SnBxcee5eaCsDWKrNVd5CoSLi3uAWx2RVoOvOnrBxcV9ltv5436Q5ZspuLi4k9w8mMq1UrHRyoe4uLi4p7l5QZMXKPlT1XYLFxd3knsihhaPUyRBhouLO8KtNjb3sdWJsMXBCS4u7lbuWoTlG6lrz+Yr4OLinuNWwyvfHMnXKYxhcHFxB7mdzYvqPYvNDy4u7ldyq6GWBFwSZJurLVxc3APczrBkw3EuXFzcQW41XE7EXHQnLi7uCLczXk0Wyg957Dr+hYuL2+D+AMBEtHvap6OjAAAAAElFTkSuQmCC" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>






<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = '死鬼去哪里了！';
            clearTimeout(titleTime);
        } else {
            document.title = '(つェ⊂)咦!又好了!';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



</body>
</html>
